<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>research | Juan Pablo Vigneaux</title> <meta name="author" content="Juan Pablo Vigneaux"> <meta name="description" content="Interests and projects"> <meta name="keywords" content="information, entropy, topology, measure-theory, category-theory, magnitude, optimal-transport,"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jpvigneaux.github.io/research/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Juan Pablo </span> Vigneaux</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item active"> <a class="nav-link" href="/research/">research<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/courses/">courses</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">research</h1> <p class="post-description">Interests and projects</p> </header> <article class="post-content"> <div id="markdown-content"> <p>I’m broadly interested in mathematical aspects of <strong>information theory</strong>, particularly in connection with category theory and geometry (metric geometry, geometric measure theory, …).</p> <p>My published work can be divided in three different areas:</p> <ul> <li><a href="#minfo-topology">Topological characterization of information measures</a></li> <li><a href="#dimension">Information dimension and measures with geometric structure</a></li> <li><a href="#magnitude">Magnitude and diversity</a></li> </ul> <p>I’ve included links to videos and slides of relevant presentations that I have given in each area, along other resources.</p> <p>I’m currently involved in two research projects in AI:</p> <ul> <li>Identification of syntactic features within LLMs (with Matilde Marcolli and Aman Burman), using layer-wise relevance propagation and some tools from mechanistic interpretability (probes, activation patching,…).</li> <li>Explanation of complex classifiers based on LLMs using an enhanced version of layer-wise relevance propagation (with Markus Marks).</li> </ul> <h2 id="minfo-topology">Topological characterization of information measures</h2> <p>In “simple” terms, <em>information topology</em> regards a statistical system as a generalized topological space (a <em>topos</em>) and identifies Shannon entropy, along other important “measures of information” used in information theory, as an <a href="https://en.wikipedia.org/wiki/Invariant_(mathematics)" rel="external nofollow noopener" target="_blank">invariant</a> associated to this space.</p> <p><a href="https://en.wikipedia.org/wiki/Topos" rel="external nofollow noopener" target="_blank">Toposes or topoi</a> are an abstraction of topological spaces in the language of category theory and sheaves introduced by Grothendieck and his collaborators (Artin, Verdier,…). Toposes allow richer cohomology theories than set-theoretic topological spaces, and some of these theories (e.g. étale cohomology) play a key role in modern algebraic geometry. Moreover, these <em>Grothendieck toposes</em> are particular cases of <em>elementary toposes</em>, which are “nice” categories with properties analogous to those of the category of sets that play an important role in logic.</p> <p>Baudot and Bennequin <a class="citation" href="#Baudot2015">(Baudot &amp; Bennequin, 2015)</a> first identified Shannon’s discrete entropy as a toposic invariant of certain categories of discrete observables. My Ph.D. thesis <a class="citation" href="#Vigneaux2019-thesis">(Vigneaux, 2019)</a> and a series of articles extended their results in several directions. Namely, the general homological constructions were abstracted from the concrete setting of discrete variables via <em>information structures</em> (categories that encode the relations of refinement between observables), allowing seamless extensions and generalizations to other settings such as continuous vector-valued observables <a class="citation" href="#Vigneaux2020information">(Vigneaux, 2020)</a>.</p> <p>When the information structure encodes discrete observables, the classical information functions—– Shannon entropy, Tsallis $\alpha$-entropy, Kullback-Leibler divergence—–appear as 1-cocycles; the corresponding “coefficients” of the cohomology are probabilistic functionals (i.e. functions of probability laws). There is also a combinatorial version of the theory (coefficients are functions of histograms) where the only 0-cocycle is the exponential function and the 1-cocycles are generalized multinomial coefficients (Fontené-Ward) <a class="citation" href="#Vigneaux2023characterization">(Vigneaux, 2023)</a>. There is an asymptotic relation between the combinatorial and probabilistic cocycles.</p> <p>For information structures that contain continuous vector-valued observables (besides discrete ones), the only new degree-one cocycles are Shannon’s differential entropy entropy and the dimension (of the support of the measure) <a class="citation" href="#Vigneaux-GSI21-cohomology">(Vigneaux, 2021)</a>. This constitutes a novel algebraic characterization of differential entropy.</p> <p>Information cohomology has seen some advances in the last years. Marcolli and Manin <a class="citation" href="#Manin2020homotopy">(Manin &amp; Marcolli, 2020)</a> related information structures with other homotopy- and category-theoretic models of neural information networks. Similar perspectives have been developed more recently by Belfiore and Bennequin <a class="citation" href="#belfiore2021topos">(Belfiore &amp; Bennequin, 2021)</a> to tackle the problem of interpretability of neural networks. They associate to each neural network a certain category equipped with a Grothendieck topology (determined by the connectivity of the neurons), and study the category of sheaves on it, which is a topos. Every topos has an internal logic, and they are linking this internal toposic logic with the classification capabilities that emerge in each layer of a trained neural network (these were previously studied in the experimental article \cite{belfiore2021logical}).</p> <p><strong>Presentations:</strong></p> <ul> <li> <a href="https://www.youtube.com/watch?v=Nzx9MotxEas" rel="external nofollow noopener" target="_blank">“Cohomological Aspects of Information” [video]</a>, Topos Institute, 2024: I summarize the main results that I have obtained in this domain.</li> <li> <a href="https://www.youtube.com/watch?v=rW76AlxMbrU" rel="external nofollow noopener" target="_blank">“Information Cohomology of Classical Vector-valued Observables” [video]</a>, GSI2021: I provide details on the characterization of the differential entropy and the dimension as the only cohomology classes in degree 1 for systems of vector-valued observables.</li> <li> <a href="https://www.youtube.com/watch?v=uYoW-pGbEWY" rel="external nofollow noopener" target="_blank">“Entropy under disintegrations” [video]</a>, GSI 2021: I explain how every disintegration of a reference measure $\lambda$ induces a chain rule for the generalized differential entropy $S(\rho) = -\int \log (\frac{d\rho}{d\lambda}) d\rho$, which gives a foundation to the extension of information cohomology to more general observables e.g. with values in locally compact topological groups.</li> <li> <a href="https://www.youtube.com/watch?v=eZqo_JcTk3I" rel="external nofollow noopener" target="_blank">“Variations on Information Theory: Categories, Cohomology, Entropy” [video]</a>, IHES, 2016: an older presentation, aimed at probabilistists, where I introduce the notion of (de Rham) cohomology and it’s analogue in our theory.</li> </ul> <p><strong>Other references:</strong></p> <ul> <li> <a href="https://tspace.library.utoronto.ca/bitstream/1807/130552/3/Dub%EF%BF%BD_Hubert_202311_PhD_thesis.pdf" rel="external nofollow noopener" target="_blank">“On the Structure of Information Cohomology”</a>, Ph.D. thesis by Hubert Dubé (U. Toronto), which introduces the Mayer-Vietoris long exact sequence, Shapiro’s lemma and Hochschild-Serre spectral sequence in the framework of information cohomology, and provides some bounds on the cohomological dimension along with new cohomological computations.</li> <li> <a href="https://sites.unimi.it/barbieri/castiglioni.pdf" rel="external nofollow noopener" target="_blank">“Information cohomology and Entropy”</a>, master thesis by Luca Castiglioni (University of Milan).</li> </ul> <h2 id="dimension">Information dimension and measures with geometric structure</h2> <p>From an analytic perspective, the <em>dimension</em> has played an important in information theory since its inception, mainly in connection with quantization. By partitioning $\Rr^d$ into cubes with vertexes in $\mathbb Z^d/n$, one might quantize a continuous probability measure $\rho$ into a measure $\rho_n$ with countable support, whose entropy satisfies \begin{equation}\label{eq:expansion_law} H(\rho_n) = D\ln n + h + o(1), \end{equation} where $D=d$ and $h=h(\rho)$ is the differential entropy of $\rho$ <a class="citation" href="#Kolmogorov1993">(Kolmogorov &amp; Shiryayev, 1993)</a>. Renyi <a class="citation" href="#Renyi1959">(Rényi, 1959)</a> turned this into a definition: if $\rho$ is now a general law and the expansion \eqref{eq:expansion_law} holds for some constants $D,h\in \Rr$, one calls $D$ the information dimension of $\rho$ and $h$ its $d$-dimensional entropy. He wondered about the “topological meaning” of the entropic dimension, which might be noninteger.</p> <p>In <a class="citation" href="#Vigneaux2023typicality">(Vigneaux, 2023)</a> I introduced an <em>asymptotic equipartition property</em> for discrete-continuous mixtures or, more generally, of convex combination of rectifiable measures on $\Rr^d$. In particular, it gives an interpretation for the information dimension $D$ of one of these measures $\rho$: the product $(\Rr^d)^n$ naturally splits into strata of different dimensions, and the typical realizations of $\rho^{\otimes n}$ concentrate on strata of a few dimensions close to $nD$. I also obtained volume estimates (in terms of Hausdorff measures) for the typical realizations in each typical stratum. (A measure $\rho$ is $m$-rectifiable if there exists a set $E$, equal to a countable union of $C^1$ manifolds, such that $\rho$ has a density with respect to the restricted HAusdorff measure $\mathcal H^m|_E$, which is the natural notion of $m$-dimensional volume on $E$.)</p> <p><strong>Presentations:</strong></p> <ul> <li> <a href="/assets/pdf/slides/GSI23-stratified.pdf">“On the entropy of rectifiable and stratified measures” [slides]</a>, GSI 2023, Saint Malò, France.</li> <li> <a href="/assets/pdf/slides/ETH-2023-stratified.pdf">“Typicality for stratified measures” [slides]</a>, ETH Zurich, 2023.</li> </ul> <h2 id="magnitude">Magnitude and diversity</h2> <p>Magnitude <a class="citation" href="#Leinster2008">(Leinster, 2008)</a> is a common categorical generalization of cardinality and of the Euler characteristic of a simplicial complex. It applies to enriched categories, of which metric spaces are a notable example, and in that case gives a new isometric invariant of metric spaces <a class="citation" href="#Leinster2013">(Leinster, 2013)</a>. Applied to infinite metric spaces, this metric invariant—somehow surprisingly—encodes a lot of nontrivial geometric information, such as Minkowski dimension, volume, surface area, etc.<a class="citation" href="#Meckes2015">(Meckes, 2015; Barceló &amp; Carbery, 2018; Gimperlein &amp; Goffeng, 2021)</a>. Partial differential equations, pseudodifferential operators and potential theory have played an important role in establishing these results.</p> <p>In joint work with Stephanie Chen <a class="citation" href="#Chen2023formula">(Chen &amp; Vigneaux, 2023)</a> (SURF program 2022), we gave a new formula for the magnitude of a finite category $\cat{A}$ in terms of the pseudoinverse of the matrix \begin{equation} \zeta:\Ob\cat{A}\times \Ob \cat{A}\to \Zz, \, (a,b)\mapsto |\Hom(a,b)|. \end{equation} This was closer to the definition for posets <a class="citation" href="#Rota1964">(Rota, 1964)</a> that had inspired Leinster. Our work also rederived algebraic properties of the magnitude from properties of the pseudoinverse.</p> <p>In <a class="citation" href="#Vigneaux2024combinatorial">(Vigneaux, 2024)</a> I propose a novel combinatorial interpretation for the inverse or pseudoinverse of $\zeta$, along the lines of <a class="citation" href="#Brualdi2008">(Brualdi &amp; Cvetkovic, 2008)</a>. The interpretation generalizes a celebrated theorem by Philip Hall <a class="citation" href="#Rota1964">(Rota, 1964)</a>: \begin{equation} \zeta^{-1}(a,b)=\sum_{k\geq 0} (-1)^k \# \{ \text{nondegenerate paths between }a\text{ and }b \} \end{equation} when $a$ and $b$ are elements of a finite poset (in this case $\zeta$ is invertible; its inverse is known as Möbius function).</p> <p>What does this have to do with information? Following Boltzmann ideas, entropy can be seen as an extension of cardinality: when all elements of a finite set $X$ are equiprobable, the entropy is $\ln |X|$. In turn, magnitude is a generalization of cardinality, and it is natural to introduce a probabilistic extension of it: “categorical entropy”. Stephanie and I <a class="citation" href="#Chen2023formula">(Chen &amp; Vigneaux, 2023)</a> proposed that categorical entropy is defined on finite categories equipped with a probability $p$ on objects and a “kernel” $\theta:\Ob\cat{A} \times \Ob \cat{A} \to [0,\infty)$ such that $\theta(a,a’)=0$ whenever $a\not\to a’$ via the formula \begin{equation}\label{eq:cat_entropy} \mathcal H(A,p,\theta) = - \sum_{a\in \Ob \cat A} p(a) \ln \left(\sum_{b\in \Ob \cat A} \theta(a,b)p(b) \right). \end{equation} This function shares many “nice” properties with Shannon entropy. In the context of metric spaces equipped with probability, \eqref{eq:cat_entropy} appears as a measure of diversity between species when $p$ is its relative abundance and $\theta$ measures their similarity <a class="citation" href="#Leinster2012">(Leinster &amp; Cobbold, 2012)</a>.</p> <p><strong>Presentations:</strong></p> <ul> <li> <a href="https://www.youtube.com/watch?v=CGzOVeQLLnA" rel="external nofollow noopener" target="_blank">“A Combinatorial Approach to Categorical Möbius Inversion and Magnitude” [video]</a>, Applied Algebraic Topology Network, 2024.</li> <li> <a href="/assets/pdf/slides/GSI23-magnitude.pdf">“Categorical Magnitude and Entropy” [slides]</a>, GSI 2023, Saint Malo, France.</li> </ul> <h1 id="bibliography">Bibliography</h1> <ol class="bibliography"> <li><span id="Baudot2015">Baudot, P., &amp; Bennequin, D. (2015). The Homological Nature of Entropy. <i>Entropy</i>, <i>17</i>(5), 3253–3318.</span></li> <li><span id="Vigneaux2019-thesis">Vigneaux, J. P. (2019). <i>Topology of Statistical Systems: A Cohomological Approach to Information Theory</i> [PhD thesis]. Université de Paris.</span></li> <li><span id="Vigneaux2020information">Vigneaux, J. P. (2020). Information structures and their cohomology. <i>Theory and Applications of Categories</i>, <i>35</i>(38), 1476–1529.</span></li> <li><span id="Vigneaux2023characterization">Vigneaux, J. P. (2023). A characterization of generalized multinomial coefficients related to the entropic chain rule. <i>Aequationes Mathematicae</i>, <i>97</i>(2), 231–255.</span></li> <li><span id="Vigneaux-GSI21-cohomology">Vigneaux, J. P. (2021). Information cohomology of classical vector-valued observables. In F. "Nielsen &amp; F. Barbaresco (Eds.), <i>GSI 2021: Geometric Science of Information</i> (Vol. 12829, pp. 537–546). Springer.</span></li> <li><span id="Manin2020homotopy">Manin, Y., &amp; Marcolli, M. (2020). Homotopy Theoretic and Categorical Models of Neural Information Networks. <i>ArXiv Preprint ArXiv:2006.15136</i>.</span></li> <li><span id="belfiore2021topos">Belfiore, J.-C., &amp; Bennequin, D. (2021). Topos and stacks of deep neural networks. <i>ArXiv Preprint ArXiv:2106.14587</i>.</span></li> <li><span id="Kolmogorov1993">Kolmogorov, A. N., &amp; Shiryayev, A. N. (1993). <i>Selected Works of A. N. Kolmogorov. Volume III: Information Theory and the Theory of Algorithms</i>. Kluwer Academic Publishers.</span></li> <li><span id="Renyi1959">Rényi, A. (1959). On the dimension and entropy of probability distributions. <i>Acta Mathematica Academiae Scientiarum Hungarica</i>, <i>10</i>(1), 193–215.</span></li> <li><span id="Vigneaux2023typicality">Vigneaux, J. P. (2023). Typicality for stratified measures. <i>IEEE Transactions on Information Theory</i>, <i>69</i>(11), 6922–6940.</span></li> <li><span id="Leinster2008">Leinster, T. (2008). The Euler Characteristic of a Category. <i>Documenta Mathematica</i>, <i>13</i>, 21–49.</span></li> <li><span id="Leinster2013">Leinster, T. (2013). The magnitude of metric spaces. <i>Documenta Mathematica</i>, <i>18</i>, 857–905.</span></li> <li><span id="Meckes2015">Meckes, M. W. (2015). Magnitude, diversity, capacities, and dimensions of metric spaces. <i>Potential Analysis</i>, <i>42</i>, 549–572.</span></li> <li><span id="Barcelo2018">Barceló, J. A., &amp; Carbery, A. (2018). On the magnitudes of compact sets in Euclidean spaces. <i>American Journal of Mathematics</i>, <i>140</i>(2), 449–494.</span></li> <li><span id="Gimperlein2021">Gimperlein, H., &amp; Goffeng, M. (2021). On the magnitude function of domains in Euclidean space. <i>American Journal of Mathematics</i>, <i>143</i>(3), 939–967.</span></li> <li><span id="Chen2023formula">Chen, S., &amp; Vigneaux, J. P. (2023). A formula for the categorical magnitude in terms of the Moore-Penrose pseudoinverse. <i>Bulletin of the Belgian Mathematical Society - Simon Stevin</i>, <i>30</i>(3), 341–353.</span></li> <li><span id="Rota1964">Rota, G.-C. (1964). On the foundations of combinatorial theory I. Theory of Möbius functions. <i>Probability Theory and Related Fields</i>, <i>2</i>(4), 340–368.</span></li> <li><span id="Vigneaux2024combinatorial">Vigneaux, J. P. (2024). A combinatorial approach to categorical Möbius inversion and pseudoinversion. <i>ArXiv Preprint 2407.14647</i>.</span></li> <li><span id="Brualdi2008">Brualdi, R. A., &amp; Cvetkovic, D. (2008). <i>A Combinatorial Approach to Matrix Theory and Its Applications</i>. CRC Press. https://books.google.com/books?id=pwx6t8QfZU8C</span></li> <li><span id="Leinster2012">Leinster, T., &amp; Cobbold, C. A. (2012). Measuring diversity: the importance of species similarity. <i>Ecology</i>, <i>93</i>(3), 477–489.</span></li> </ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2025 Juan Pablo Vigneaux. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: January 25, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams",inlineMath:[["$","$"],["\\(","\\)"]],processEscapes:!0,macros:{salg:"{\\mathfrak}",Rr:"{\\mathbb{R}}",Cc:"{\\mathbb{C}}",Nn:"{\\mathbb{N}}",Qq:"{\\mathbb{Q}}",Zz:"{\\mathbb{Z}}",Ff:"{\\mathbb{F}}",Ex:"{\\mathbin{\\mathbb{E}}}",Pr:"{\\mathbin{\\mathbb{P}}}",Var:"{\\mathbin{\\mathbf{Var}}}",Tr:["{\\operatorname{Tr}\\left( #1\\right)}",1],Bin:"{\\operatorname{Bin}}",Ber:"{\\operatorname{Ber}}",Hom:"{\\operatorname{Hom}}",Ext:"{\\operatorname{Ext}}",Tor:"{\\operatorname{Tor}}",ker:"{\\operatorname{ker}}",coker:"{\\operatorname{coker}}",im:"{\\operatorname{im}}",coim:"{\\operatorname{coim}}",monic:"{\\rightarrowtail}",epic:"{\\twoheadrightarrow}",tr:"{^{\\rm T}}",rank:"{\\operatorname{rank}}",id:"{\\operatorname{id}}",Ob:"{\\operatorname{Ob}}",Mor:"{\\operatorname{Mor}}",sheaf:["{\\mathcal{#1}}",1],cat:["{\\mathbf{#1}}",1],vol:"{\\operatorname{vol}}"}}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-6B8Q37P9Y6"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-6B8Q37P9Y6");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>